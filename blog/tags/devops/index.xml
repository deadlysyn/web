<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>devops on Hello World</title><link>https://deadlysyn.com/blog/tags/devops/</link><description>Recent content in devops on Hello World</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 10 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://deadlysyn.com/blog/tags/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Safely Expose Credentials</title><link>https://deadlysyn.com/blog/posts/safely-expose-credentials/</link><pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/safely-expose-credentials/</guid><description>If you&amp;rsquo;re juggling STS credentials while wrangling more AWS accounts than you can count, you&amp;rsquo;ve likely heard of aws-vault. Aside from the convenience factor, it&amp;rsquo;s also good for security (keep plain-text credentials off disk).
Similarly, it&amp;rsquo;s obvious you don&amp;rsquo;t want to commit credentials. Depending how far you take that, even committing encrypted credentials (or storing them anywhere not intended for managing secrets) should be discouraged.
One reason is building up muscle memory and inviting accidental commits of unencrypted secrets (use something like gitleaks to prevent that).</description></item><item><title>Lean IAM Management</title><link>https://deadlysyn.com/blog/posts/lean-aws-iam/</link><pubDate>Sun, 16 Jan 2022 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/lean-aws-iam/</guid><description>Part of DevOps culture is avoiding tickets when automation can provide lower-friction alternatives. Similarly, the SRE mindset seeks to eliminate toil. We also know from experience that the most effective Agile teams are granted a high level of autonomy.
IAM is a routine stumbling block to autonomy. Teams need an &amp;ldquo;appropriate&amp;rdquo; level of access to do their job. That often turns into waiting on tickets, with another team twiddling bits to unblock development.</description></item><item><title>Go Datadog CLI</title><link>https://deadlysyn.com/blog/posts/go-datadog-cli/</link><pubDate>Mon, 29 Nov 2021 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/go-datadog-cli/</guid><description>I found myself wrapping ChatOps around a CI/CD pipeline to manage scheduled downtime in DataDog (avoiding SLO impact for planned work). For astute readers wondering why this wasn&amp;rsquo;t a direct API call; I tend to (ab)use CI as a generic task runner (has an API, secret store, etc).
I wanted to identify resources using labels (team:foo, service:bar). While this is a common use case and things have hopefully improved, CLIs available at the time provided numerous ways to manage downtime but lacked tag support.</description></item><item><title>Automating ECS</title><link>https://deadlysyn.com/blog/posts/automating-ecs/</link><pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/automating-ecs/</guid><description>Clone the project repo to follow along&amp;hellip;
So far in this series we&amp;rsquo;ve learned the fundamentals of Amazon&amp;rsquo;s Elastic Container Service, containerized a simple Node.js application, and deployed it to the cloud. In the final article of this series, we&amp;rsquo;ll eliminate the toil of building and maintaining ECS infrastructure by automating everything we&amp;rsquo;ve learned using Terraform.
Container Definition Before diving into Terraform, the first thing we&amp;rsquo;ll need is a &amp;ldquo;container definition&amp;rdquo; to feed the aws_ecs_task_definition resource.</description></item><item><title>ECS Task Definitions</title><link>https://deadlysyn.com/blog/posts/ecs-task-definitions/</link><pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/ecs-task-definitions/</guid><description>Clone the project repo to follow along&amp;hellip;
In the first two parts of our multi-part series on shipping containerized Node.js apps using the AWS Elastic Container Service, we looked at how to Dockerize our app and get it ready to ship by using the Elastic Container Registry. This time we&amp;rsquo;re going to dive into an essential piece of ECS-specific configuration known as Task Definitions. Like anything new, this may seem daunting at first&amp;hellip; but with a little exploration we&amp;rsquo;ll gain enough knowledge to start feeling comfortable.</description></item><item><title>Contain Yourself</title><link>https://deadlysyn.com/blog/posts/contain-yourself/</link><pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/contain-yourself/</guid><description>Clone the project repo to follow along&amp;hellip;
In part one of this series we walked through using Docker to containerize a simple Node.js app and verified our shiny new container worked as expected. Unfortunately, containers aren&amp;rsquo;t much use if we can&amp;rsquo;t get them deployed to start delighting users with the sheer awesomeness of our brilliant code.
In the container world, the path to production involves some sort of registry&amp;hellip; While it sounds fancy, a registry isn&amp;rsquo;t much different from the simple web servers you historically used to host RPMs or DEBs (essentially just another tool to help you maintain the ITIL concept of a Definitive Software Library.</description></item><item><title>Thinking Inside the Box</title><link>https://deadlysyn.com/blog/posts/thinking-inside-the-box/</link><pubDate>Sun, 08 Mar 2020 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/thinking-inside-the-box/</guid><description>Clone the project repo to follow along&amp;hellip;
This is going to be another multi-part series&amp;hellip; I don&amp;rsquo;t want to get too far ahead of myself, but the end goal is shipping a Node.js app using Amazon Web Service&amp;rsquo;s Elastic Container Service (ECS). We have to crawl before we can walk (or run an app), so this first article will cover the basics of getting a simple Node app containerized (feel free to plug in whatever app you want).</description></item><item><title>Squashing Bugs</title><link>https://deadlysyn.com/blog/posts/squashing-bugs/</link><pubDate>Fri, 22 Nov 2019 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/squashing-bugs/</guid><description>Clone the companion project to follow along&amp;hellip;
In a recent multi-part series on Terraforming a simple N-tier stack atop AWS, we provisioned a number of public and private subnets. We used CIDR ranges provided as input variables and the cidrsubnet function to automatically carve out smaller subnets based on the number of AZs in the target region.
As originally mentioned, this was an attempt to follow typical HA best practices (not having all resources in a single AZ) and meet RDS subnet group requirements.</description></item><item><title>Terraforming AWS: Part III</title><link>https://deadlysyn.com/blog/posts/terraforming-aws-part-iii/</link><pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/terraforming-aws-part-iii/</guid><description>Clone the companion project to follow along&amp;hellip;
So far in Part I and Part II of this series we have provisioned a multi-AZ network with custom VPC, subnets, internet gateway and routing tables then deployed highly-available, auto-scaling Linux servers using EC2 and ALB. Our multi-tier starter project only has one big piece remaining â€“ the database!
In the final part of this series we&amp;rsquo;ll explore AWS&amp;rsquo; Relational Database Service (RDS). More than simply moving your database to the cloud, RDS provides numerous DBaaS advantages including fault tolerance, automated backups, and easy upgrades.</description></item><item><title>Terraforming AWS: Part II</title><link>https://deadlysyn.com/blog/posts/terraforming-aws-part-ii/</link><pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/terraforming-aws-part-ii/</guid><description>Clone the companion project to follow along&amp;hellip;
In Part I of this series [/blog/posts/terraforming-aws-part-i], we worked through a lot of AWS fundamentals and bootstrapped a network including custom VPC, public and private subnets and route tables. Thanks to that foundation, this and subsequent parts will be able to focus on more condensed code and make quicker progress.
In this tutorial, we can move onto something more exciting: EC2 (Elastic Compute Cloud) and ALB (Application Load Balancing).</description></item><item><title>Terraforming AWS: Part I</title><link>https://deadlysyn.com/blog/posts/terraforming-aws-part-i/</link><pubDate>Sun, 10 Nov 2019 00:00:00 +0000</pubDate><guid>https://deadlysyn.com/blog/posts/terraforming-aws-part-i/</guid><description>Clone the companion project to follow along&amp;hellip;
When you hear &amp;ldquo;Cloud Computing&amp;rdquo;, the first thing that likely comes to mind is Amazon Web Services. Aside from record reliability and one of the largest infrastructure footprints in the world, they provide a diverse service catalog serving as an erector set any engineer can use to build ready-made infrastructures.
Similarly, HashiCorp&amp;rsquo;s Terraform has become a staple of the DevOps toolbox. With a flexible DSL and diverse provider ecosystem supporting every major cloud provider, Terraform went from relative newcomer to ubiquitous automation standard within a few years.</description></item></channel></rss>